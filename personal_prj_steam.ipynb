{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIBRARIES USED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import spacy\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. DATA SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_games = [\n",
    "    #RPG\n",
    "    \"Dota 2\",\n",
    "    \"The Elder Scrolls V: Skyrim\",\n",
    "    \"The Witcher 3: Wild Hunt\",\n",
    "\n",
    "    #FPS\n",
    "    \"Call of Duty: Modern Warfare 3\",\n",
    "    \"Counter-Strike\",\n",
    "    \"DOOM\",\n",
    "\n",
    "    #Sports\n",
    "    \"NBA 2K16\",\n",
    "    \"Rocket League\",\n",
    "    \"Football Manager 2016\"\n",
    "    ]\n",
    "\n",
    "df_filtered_games = original_df[original_df['app_name'].isin(chosen_games)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>Ruined my life.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>This will be more of a ''my experience with th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>This game saved my virginity.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>• Do you like original games? • Do you like ga...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>Easy to learn, hard to master.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app_id        app_name                                        review_text  \\\n",
       "0      10  Counter-Strike                                    Ruined my life.   \n",
       "1      10  Counter-Strike  This will be more of a ''my experience with th...   \n",
       "2      10  Counter-Strike                      This game saved my virginity.   \n",
       "3      10  Counter-Strike  • Do you like original games? • Do you like ga...   \n",
       "4      10  Counter-Strike           Easy to learn, hard to master.             \n",
       "\n",
       "   review_score  review_votes  \n",
       "0             1             0  \n",
       "1             1             1  \n",
       "2             1             0  \n",
       "3             1             0  \n",
       "4             1             1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_games.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. DATA PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 204389 entries, 0 to 6257360\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   app_id        204389 non-null  int64 \n",
      " 1   app_name      204389 non-null  object\n",
      " 2   review_text   204127 non-null  object\n",
      " 3   review_score  204389 non-null  int64 \n",
      " 4   review_votes  204389 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_filtered_games.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 204127 entries, 0 to 6257360\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   app_id        204127 non-null  int64 \n",
      " 1   app_name      204127 non-null  object\n",
      " 2   review_text   204127 non-null  object\n",
      " 3   review_score  204127 non-null  int64 \n",
      " 4   review_votes  204127 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 9.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_filtered_games = df_filtered_games.dropna(subset=['review_text'])\n",
    "\n",
    "df_filtered_games.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kevanteo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/kevanteo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download stopwords and punkt if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    \n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove non-alphanumeric characters\n",
    "    \n",
    "    tokens = word_tokenize(text)  # Tokenize text\n",
    "    \n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Remove stopwords\n",
    "    \n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatize each word\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply the function to the review_text column\n",
    "df_filtered_games['cleaned_review_text'] = df_filtered_games['review_text'].apply(lambda x: preprocess_text(x) if isinstance(x, str) else x)\n",
    "\n",
    "# 13 minutes to run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>cleaned_review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ruined my life.</td>\n",
       "      <td>ruined life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This will be more of a ''my experience with th...</td>\n",
       "      <td>experience game type review saying thing like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This game saved my virginity.</td>\n",
       "      <td>game saved virginity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>• Do you like original games? • Do you like ga...</td>\n",
       "      <td>like original game like game dont lag like gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Easy to learn, hard to master.</td>\n",
       "      <td>easy learn hard master</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0                                    Ruined my life.   \n",
       "1  This will be more of a ''my experience with th...   \n",
       "2                      This game saved my virginity.   \n",
       "3  • Do you like original games? • Do you like ga...   \n",
       "4           Easy to learn, hard to master.             \n",
       "\n",
       "                                 cleaned_review_text  \n",
       "0                                        ruined life  \n",
       "1  experience game type review saying thing like ...  \n",
       "2                               game saved virginity  \n",
       "3  like original game like game dont lag like gam...  \n",
       "4                             easy learn hard master  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_games[['review_text', 'cleaned_review_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 204127 entries, 0 to 6257360\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   app_id               204127 non-null  int64 \n",
      " 1   app_name             204127 non-null  object\n",
      " 2   review_text          204127 non-null  object\n",
      " 3   review_score         204127 non-null  int64 \n",
      " 4   review_votes         204127 non-null  int64 \n",
      " 5   cleaned_review_text  204127 non-null  object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 10.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_filtered_games.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which rows have missing values (NaN) in the 'cleaned_review_text' column\n",
    "missing_rows = df_filtered_games[df_filtered_games['cleaned_review_text'].isnull()]\n",
    "\n",
    "# Display the rows with missing values\n",
    "print(missing_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x0/rmy2hc015hb0qlcj8q1rdvsw0000gn/T/ipykernel_40072/1101054237.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_filtered_games['cleaned_review_text'].replace('',np.nan,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_filtered_games['cleaned_review_text'].replace('',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 204127 entries, 0 to 6257360\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   app_id               204127 non-null  int64 \n",
      " 1   app_name             204127 non-null  object\n",
      " 2   review_text          204127 non-null  object\n",
      " 3   review_score         204127 non-null  int64 \n",
      " 4   review_votes         204127 non-null  int64 \n",
      " 5   cleaned_review_text  200242 non-null  object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 10.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_filtered_games.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_games = df_filtered_games.dropna(subset=['cleaned_review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 200242 entries, 0 to 6257360\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   app_id               200242 non-null  int64 \n",
      " 1   app_name             200242 non-null  object\n",
      " 2   review_text          200242 non-null  object\n",
      " 3   review_score         200242 non-null  int64 \n",
      " 4   review_votes         200242 non-null  int64 \n",
      " 5   cleaned_review_text  200242 non-null  object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 10.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_filtered_games.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_games.to_csv('pre_processed_reviews.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_votes</th>\n",
       "      <th>cleaned_review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>Ruined my life.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ruined life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>This will be more of a ''my experience with th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>experience game type review saying thing like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>This game saved my virginity.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>game saved virginity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>• Do you like original games? • Do you like ga...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>like original game like game dont lag like gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>Easy to learn, hard to master.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>easy learn hard master</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app_id        app_name                                        review_text  \\\n",
       "0      10  Counter-Strike                                    Ruined my life.   \n",
       "1      10  Counter-Strike  This will be more of a ''my experience with th...   \n",
       "2      10  Counter-Strike                      This game saved my virginity.   \n",
       "3      10  Counter-Strike  • Do you like original games? • Do you like ga...   \n",
       "4      10  Counter-Strike           Easy to learn, hard to master.             \n",
       "\n",
       "   review_score  review_votes  \\\n",
       "0             1             0   \n",
       "1             1             1   \n",
       "2             1             0   \n",
       "3             1             0   \n",
       "4             1             1   \n",
       "\n",
       "                                 cleaned_review_text  \n",
       "0                                        ruined life  \n",
       "1  experience game type review saying thing like ...  \n",
       "2                               game saved virginity  \n",
       "3  like original game like game dont lag like gam...  \n",
       "4                             easy learn hard master  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('pre_processed_reviews.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200242 entries, 0 to 200241\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   app_id               200242 non-null  int64 \n",
      " 1   app_name             200242 non-null  object\n",
      " 2   review_text          200242 non-null  object\n",
      " 3   review_score         200242 non-null  int64 \n",
      " 4   review_votes         200242 non-null  int64 \n",
      " 5   cleaned_review_text  200242 non-null  object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/kevanteo/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "#Sentiment Analysis\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df['sentiment'] = df['review_text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "# 1 minute 30 seconds to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_votes</th>\n",
       "      <th>cleaned_review_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>Ruined my life.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ruined life</td>\n",
       "      <td>-0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>This will be more of a ''my experience with th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>experience game type review saying thing like ...</td>\n",
       "      <td>0.9954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>This game saved my virginity.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>game saved virginity</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>• Do you like original games? • Do you like ga...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>like original game like game dont lag like gam...</td>\n",
       "      <td>0.9098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>Easy to learn, hard to master.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>easy learn hard master</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app_id        app_name                                        review_text  \\\n",
       "0      10  Counter-Strike                                    Ruined my life.   \n",
       "1      10  Counter-Strike  This will be more of a ''my experience with th...   \n",
       "2      10  Counter-Strike                      This game saved my virginity.   \n",
       "3      10  Counter-Strike  • Do you like original games? • Do you like ga...   \n",
       "4      10  Counter-Strike           Easy to learn, hard to master.             \n",
       "\n",
       "   review_score  review_votes  \\\n",
       "0             1             0   \n",
       "1             1             1   \n",
       "2             1             0   \n",
       "3             1             0   \n",
       "4             1             1   \n",
       "\n",
       "                                 cleaned_review_text  sentiment  \n",
       "0                                        ruined life    -0.4767  \n",
       "1  experience game type review saying thing like ...     0.9954  \n",
       "2                               game saved virginity     0.4215  \n",
       "3  like original game like game dont lag like gam...     0.9098  \n",
       "4                             easy learn hard master     0.3612  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking for Contradicting Reviews\n",
    "- These will require human intervention/expertise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_review_text</th>\n",
       "      <th>review_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>contradicting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ruined life</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>experience game type review saying thing like ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>game saved virginity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like original game like game dont lag like gam...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>easy learn hard master</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 cleaned_review_text  review_score  sentiment  \\\n",
       "0                                        ruined life             1    -0.4767   \n",
       "1  experience game type review saying thing like ...             1     0.9954   \n",
       "2                               game saved virginity             1     0.4215   \n",
       "3  like original game like game dont lag like gam...             1     0.9098   \n",
       "4                             easy learn hard master             1     0.3612   \n",
       "\n",
       "   contradicting  \n",
       "0              1  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to detect contradicting reviews\n",
    "def detect_contradicting_reviews(row):\n",
    "    # Check for rating-text mismatch\n",
    "    if row['review_score'] == 1 and row['sentiment'] < 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['contradicting'] = df.apply(detect_contradicting_reviews, axis=1)\n",
    "\n",
    "df[['cleaned_review_text', 'review_score', 'sentiment', 'contradicting']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a new DataFrame with contradicting reviews\n",
    "contradicting_review = df[df['contradicting'] == 1]\n",
    "\n",
    "# Step 2: Drop the contradicting reviews from the original DataFrame\n",
    "df = df[df['contradicting'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "contradicting_review.to_csv('contradicting_reviews.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contradicting\n",
      "0    178459\n",
      "Name: count, dtype: int64\n",
      "review_score\n",
      " 1    157578\n",
      "-1     20881\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['contradicting'].value_counts())\n",
    "\n",
    "print(df['review_score'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_votes</th>\n",
       "      <th>cleaned_review_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>contradicting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>This will be more of a ''my experience with th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>experience game type review saying thing like ...</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>This game saved my virginity.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>game saved virginity</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>• Do you like original games? • Do you like ga...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>like original game like game dont lag like gam...</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>Easy to learn, hard to master.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>easy learn hard master</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>No r8 revolver, 10/10 will play again.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>r8 revolver 1010 play</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app_id        app_name                                        review_text  \\\n",
       "1      10  Counter-Strike  This will be more of a ''my experience with th...   \n",
       "2      10  Counter-Strike                      This game saved my virginity.   \n",
       "3      10  Counter-Strike  • Do you like original games? • Do you like ga...   \n",
       "4      10  Counter-Strike           Easy to learn, hard to master.             \n",
       "5      10  Counter-Strike             No r8 revolver, 10/10 will play again.   \n",
       "\n",
       "   review_score  review_votes  \\\n",
       "1             1             1   \n",
       "2             1             0   \n",
       "3             1             0   \n",
       "4             1             1   \n",
       "5             1             1   \n",
       "\n",
       "                                 cleaned_review_text  sentiment  contradicting  \n",
       "1  experience game type review saying thing like ...     0.9954              0  \n",
       "2                               game saved virginity     0.4215              0  \n",
       "3  like original game like game dont lag like gam...     0.9098              0  \n",
       "4                             easy learn hard master     0.3612              0  \n",
       "5                              r8 revolver 1010 play     0.0516              0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 178459 entries, 1 to 200241\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   app_id               178459 non-null  int64  \n",
      " 1   app_name             178459 non-null  object \n",
      " 2   review_text          178459 non-null  object \n",
      " 3   review_score         178459 non-null  int64  \n",
      " 4   review_votes         178459 non-null  int64  \n",
      " 5   cleaned_review_text  178459 non-null  object \n",
      " 6   sentiment            178459 non-null  float64\n",
      " 7   contradicting        178459 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(3)\n",
      "memory usage: 12.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000</th>\n",
       "      <th>000000</th>\n",
       "      <th>0000000</th>\n",
       "      <th>00000000</th>\n",
       "      <th>0000000000</th>\n",
       "      <th>00000000000</th>\n",
       "      <th>0000000000000</th>\n",
       "      <th>...</th>\n",
       "      <th>zynga</th>\n",
       "      <th>zyzz</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzz</th>\n",
       "      <th>zzzz</th>\n",
       "      <th>zzzzquiet</th>\n",
       "      <th>zzzzz</th>\n",
       "      <th>zzzzzz</th>\n",
       "      <th>zzzzzzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85715 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  00000  000000  0000000  00000000  0000000000  00000000000  \\\n",
       "0   0    0     0      0       0        0         0           0            0   \n",
       "1   0    0     0      0       0        0         0           0            0   \n",
       "2   0    0     0      0       0        0         0           0            0   \n",
       "3   0    0     0      0       0        0         0           0            0   \n",
       "4   0    0     0      0       0        0         0           0            0   \n",
       "\n",
       "   0000000000000  ...  zynga  zyzz  zz  zzz  zzzz  zzzzquiet  zzzzz  zzzzzz  \\\n",
       "0              0  ...      0     0   0    0     0          0      0       0   \n",
       "1              0  ...      0     0   0    0     0          0      0       0   \n",
       "2              0  ...      0     0   0    0     0          0      0       0   \n",
       "3              0  ...      0     0   0    0     0          0      0       0   \n",
       "4              0  ...      0     0   0    0     0          0      0       0   \n",
       "\n",
       "   zzzzzzzzzzzz  zzzzzzzzzzzzzzzzzzz  \n",
       "0             0                    0  \n",
       "1             0                    0  \n",
       "2             0                    0  \n",
       "3             0                    0  \n",
       "4             0                    0  \n",
       "\n",
       "[5 rows x 85715 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the cleaned_review_text column\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['cleaned_review_text'].dropna())\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame (using sparse matrix format)\n",
    "tfidf_df = pd.DataFrame.sparse.from_spmatrix(tfidf_matrix, columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero entries: 3262885\n",
      "Total elements: 15296613185\n"
     ]
    }
   ],
   "source": [
    "nonzero_count = tfidf_matrix.nnz\n",
    "total_elements = tfidf_matrix.shape[0] * tfidf_matrix.shape[1]\n",
    "print(\"Non-zero entries:\", nonzero_count)\n",
    "print(\"Total elements:\", total_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002        0.089796\n",
      "2008        0.085228\n",
      "account     0.063544\n",
      "advanced    0.069229\n",
      "ago         0.058626\n",
      "              ...   \n",
      "way         0.117726\n",
      "week        0.057115\n",
      "wish        0.053154\n",
      "wouldnt     0.117854\n",
      "year         0.03931\n",
      "Name: 0, Length: 136, dtype: Sparse[float64, 0]\n"
     ]
    }
   ],
   "source": [
    "# Print the nonzero tokens for the first review\n",
    "nonzero_tokens = tfidf_df.iloc[0][tfidf_df.iloc[0] != 0]\n",
    "print(nonzero_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero counts for each row: [136   3  13 ...   3 123  23]\n"
     ]
    }
   ],
   "source": [
    "nonzero_per_row = tfidf_matrix.getnnz(axis=1)\n",
    "print(\"Nonzero counts for each row:\", nonzero_per_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(['app_id','review_votes','app_name','sentiment','contradicting','review_text'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT:\n",
    "# The tfidf_matrix should have been computed on df['cleaned_review_text'].dropna()\n",
    "# so its rows correspond to df_clean.\n",
    "# If that’s not the case, re-run the vectorization on df_clean, e.g.:\n",
    "# tfidf_matrix = tfidf_vectorizer.fit_transform(df_clean['cleaned_review_text'])\n",
    "\n",
    "# Define features and target\n",
    "X = tfidf_matrix          # TF-IDF features (sparse matrix)\n",
    "y = df['review_score']  # Target variable: 1 (positive/recommend) or -1 (negative/not recommend)\n",
    "\n",
    "# --- Train-Test Split ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- Oversampling using SMOTE ---\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Training ---\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the Logistic Regression classifier\n",
    "lr = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "lr.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# --- Model Evaluation ---\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of tfidf_matrix\n",
    "print(\"Shape of tfidf_matrix:\", tfidf_matrix.shape)\n",
    "\n",
    "# Check the number of rows in df_clean\n",
    "print(\"Number of rows in df_clean:\", df_clean.shape[0])\n",
    "\n",
    "# Verify if they match\n",
    "if tfidf_matrix.shape[0] == df_clean.shape[0]:\n",
    "    print(\"tfidf_matrix was computed on df_clean['cleaned_review_text']\")\n",
    "else:\n",
    "    print(\"tfidf_matrix was NOT computed on df_clean['cleaned_review_text']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the SVM classifier\n",
    "svm = SVC(kernel='linear', class_weight='balanced', random_state=42)\n",
    "svm.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Export the SVM model to a file\n",
    "joblib.dump(svm, 'svm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize and train the Gradient Boosting classifier\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gradient_boosting_model.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Export the Random Forest model to a file\n",
    "joblib.dump(rf, 'random_forest_model.pkl')\n",
    "\n",
    "# Export the Gradient Boosting model to a file\n",
    "joblib.dump(gb, 'gradient_boosting_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>review_score</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_review_text</th>\n",
       "      <th>sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>1</td>\n",
       "      <td>['experience', 'game', 'type', 'review', 'sayi...</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>experience game type review saying things like...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>1</td>\n",
       "      <td>['game', 'saved', 'virginity']</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>game saved virginity</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>1</td>\n",
       "      <td>['like', 'original', 'games', 'like', 'games',...</td>\n",
       "      <td>0.8817</td>\n",
       "      <td>like original games like games dont lag like g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>1</td>\n",
       "      <td>['easy', 'learn', 'hard', 'master']</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>easy learn hard master</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>1</td>\n",
       "      <td>['r', 'revolver', 'play']</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>r revolver play</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app_id        app_name  review_score  \\\n",
       "1      10  Counter-Strike             1   \n",
       "2      10  Counter-Strike             1   \n",
       "3      10  Counter-Strike             1   \n",
       "4      10  Counter-Strike             1   \n",
       "5      10  Counter-Strike             1   \n",
       "\n",
       "                                              tokens  sentiment  \\\n",
       "1  ['experience', 'game', 'type', 'review', 'sayi...     0.9961   \n",
       "2                     ['game', 'saved', 'virginity']     0.4215   \n",
       "3  ['like', 'original', 'games', 'like', 'games',...     0.8817   \n",
       "4                ['easy', 'learn', 'hard', 'master']     0.3612   \n",
       "5                          ['r', 'revolver', 'play']     0.0516   \n",
       "\n",
       "                                 cleaned_review_text  sarcasm  \n",
       "1  experience game type review saying things like...        0  \n",
       "2                               game saved virginity        0  \n",
       "3  like original games like games dont lag like g...        0  \n",
       "4                             easy learn hard master        0  \n",
       "5                                    r revolver play        0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"cleaned_review_text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "df_clean['review_score'] = df_clean['review_score'].apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 176357/176357 [01:09<00:00, 2543.02 examples/s]\n",
      "c:\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8416\\4280998099.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "c:\\Python312\\Lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52908' max='52908' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52908/52908 1:10:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>0.369587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.306400</td>\n",
       "      <td>0.325510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.241900</td>\n",
       "      <td>0.266819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5326' max='4409' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4409/4409 10:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.2668187618255615, 'eval_runtime': 58.7291, 'eval_samples_per_second': 600.589, 'eval_steps_per_second': 75.074, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Convert to Hugging Face dataset\n",
    "dataset = Dataset.from_pandas(df_clean)\n",
    "dataset = dataset.map(tokenize_function, batched=True)\n",
    "dataset = dataset.remove_columns([\"tokens\"])\n",
    "dataset = dataset.rename_column(\"review_score\", \"labels\")\n",
    "dataset.set_format(\"torch\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Split dataset\n",
    "train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "test_dataset = train_test_split[\"test\"]\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "# Define trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_results\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[10], line 39\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[1;34m(eval_pred)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_metrics\u001b[39m(eval_pred):\n\u001b[1;32m---> 39\u001b[0m     logits, labels \u001b[38;5;241m=\u001b[39m eval_pred\n\u001b[0;32m     40\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy_score(labels, predictions)}\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save model and tokenizer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./saved_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./saved_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Save model and tokenizer\n",
    "model.save_pretrained(\"./saved_model\")\n",
    "tokenizer.save_pretrained(\"./saved_model\")\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cpu\n",
      "0.34.2\n",
      "4.49.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import accelerate\n",
    "import transformers\n",
    "print(torch.__version__)\n",
    "print(accelerate.__version__)\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "# from nltk.corpus import stopwords, wordnet\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# import nltk\n",
    "\n",
    "# # Download required resources\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# stop_words = set(stopwords.words('english'))  # Load stopwords once\n",
    "\n",
    "# # Define a function to preprocess text\n",
    "# def preprocess_text(text):\n",
    "#     text = text.lower()  # Convert to lowercase\n",
    "#     text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "#     tokens = word_tokenize(text)  # Tokenize text\n",
    "#     tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
    "    \n",
    "#     # Get POS tags and lemmatize accordingly\n",
    "#     pos_tags = pos_tag(tokens)\n",
    "#     tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "\n",
    "#     return ' '.join(tokens)\n",
    "\n",
    "# # Apply the function to the review_text column\n",
    "# df['cleaned_review_text'] = df['review_text'].apply(lambda x: preprocess_text(x) if isinstance(x, str) else x)\n",
    "\n",
    "# print(df[['review_text', 'cleaned_review_text']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
